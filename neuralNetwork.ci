mainmodule neuralNetwork {

  include "Neuron.h";
  readonly CProxy_Main mainProxy;
  /*
    Vector containing all the layers Proxies.
    This is neccesary for accessing the chares on the different layers
  */
  readonly std::vector<CProxy_NeuronGroup> layerProxies;
  readonly std::map<unsigned int, unsigned int> mapLayerToNeurons;
  readonly std::vector< double > oracle;

  readonly unsigned int inputNeurons;
  readonly unsigned int nMiddleLayers;
  readonly unsigned int middleLayersNeurons;
  readonly unsigned int outputNeurons;
  readonly unsigned int neuronsPerChare;
  readonly unsigned int totalLayers;

  mainchare Main {
    entry Main(CkArgMsg* m);
    /*
      Reduction target after the forward operation
      Change internal states of the neurons for backpropagation
    */
    //entry [reductiontarget] void doneForwardContribution();
    //entry [reductiontarget] void doneBackwardContribution();
      entry [reductiontarget] void totalNeurons(int total);
      entry [reductiontarget] void creationDone();
      entry [reductiontarget] void initializationDone();
      entry [reductiontarget] void forwardComplete();
      entry [reductiontarget] void done();
  };

  /*
    Representation: 1D array of chares for each layer. s
    Each chare will containg X neurons, where X gives us the granularity
  */
  array [1D] NeuronGroup { //An array of NeuronGroup is a layer
    entry NeuronGroup(int layer, int nNeurons);
    entry void sendForward (int iter, int layer, int groupId, std::vector<double> incoming);
    entry void sendBackward(int iter, int layer, int groupId, std::vector<double> errors);
    entry void activate();
    entry void collectValues();
    entry void collectValues(int image_id);
    entry void calculateOutputError();

    entry void collectErrors();
    entry void calculateErrors();
    //entry void exportErrors(vector<vector<double>> &errorBuffer);
    //entry void updateWeight();
    entry void setInputVector( std::vector< std::vector<double> >);

    //Main computation
    entry void runForward() {

        //Iteration is the number of images we have as input.
        for(iteration=0; iteration<ITERATION; iteration++){

          /*
            Prepare the input for the iteration
            This is loading each pixel of the image, to be send
            to the input layer.
          */

          if (layerIndex == 0) // Input Layer
          {
            serial {
              //collectValues();
	      collectValues(iteration);
              layerProxies.at(1).sendForward(iteration, layerIndex, thisIndex, values );
            }
          }

          if (layerIndex > 0 && layerIndex < totalLayers - 1) //Hidden Layers
          {

            forall [block](0: mapLayerToNeurons[layerIndex - 1]/neuronsPerChare -1,1) //Receiving from all the chares in layer-1
              when sendForward[iteration](int iter, int layer, int groupId, std::vector<double> incoming  )
                serial "receiveAndsendValues" 
                {   //Receives from layer layerIndex - 1

                  for (i = 0; i < incoming.size(); ++i)
                  {
                    incomingAj.at(groupId*neuronsPerChare + i)=incoming.at(i);
                  }

                  //CkPrintf("Layer %2d Group %2d Receiving %d from layer %2d \n", layerIndex, thisIndex, incoming.size(), layer);
                }

            serial {
                /*
                 *  Do the weight operation and deliver the weight value to each cell
                 */
                activate();
                collectValues();
                layerProxies.at(layerIndex + 1).sendForward(iteration, layerIndex, thisIndex, values );
            }
          }

          if (layerIndex == totalLayers - 1) //output Layer
          {
            forall [block](0: middleLayersNeurons/neuronsPerChare -1,1)
              when sendForward[iteration](int iter, int layer, int groupId, std::vector<double> incoming  )
                //Receives from layer thisLayerIndex - 1
                serial "recevingLastLayer" {
		  char valuesStr[10000];
		  valuesStr[0] = '\0';
		  for (i = 0; i < incoming.size(); ++i)
                  {
                    incomingAj.at(groupId*neuronsPerChare + i) = incoming.at(i);
		    char numStr[50];
		    sprintf(numStr, " %lf", incoming.at(i));
		    strcat(valuesStr, numStr);
                  }
                  CkPrintf("Layer %2d Group: %d Receiving [%d-%d] %s from Layer %2d Group %d\n", layerIndex, thisIndex, groupId*neuronsPerChare, ((groupId+1)*neuronsPerChare)-1, valuesStr, layer, groupId);
                }

                serial "calculatingError" {
                  activate();
                  //printValues();
                  calculateOutputError();
                }
          }
 	 
	/* 
	  if (iteration % BACKWARD_FREQ == 0) {
	      serial {
		 runBackward(); //Go to backward phase every BACKWARD_FREQ iterations
	      }
	  }
	*/ 

        }//end of the iteration loop

    };//end of runForward

     entry void runBackward() {

          if (layerIndex > 0 && layerIndex < totalLayers - 1) //Hidden Layers
          {
            forall [block](0: mapLayerToNeurons[layerIndex + 1]/neuronsPerChare -1,1) //Receiving from all the chares in layer-1
              when sendBackward[iteration](int iter, int layer, int groupId, std::vector<double> errors  )
                serial "receiveAndsendErrors" {
                  //Receives from layer layerIndex + 1

                  for (i = 0; i < errors.size(); ++i)
                  {
                    incomingErrs.at(groupId*neuronsPerChare + i) = errors.at(i);
                  }
                  CkPrintf("Layer %2d Group %2d Receiving errors from layer %2d \n", layerIndex, thisIndex, layer);
                }

            serial {
                /*
                 *  Calculate the errors for this layer and update weights
                 */
                calculateErrors();
                collectErrors();
                if (layerIndex - 1 != 0)
                {
                  layerProxies.at(layerIndex - 1).sendBackward(iteration, layerIndex, thisIndex, errors);
                }
                
                CkPrintf("Layer %2d Done \n", layerIndex);
            }
          }

         if (layerIndex == totalLayers - 1) //output Layer
         {
            serial {
              /*
               Error has been updated in the forward phase
              */
              collectErrors();
              layerProxies.at(layerIndex - 1).sendBackward(iteration, layerIndex, thisIndex, errors );
           }
         }

      };//end of runBackward

    };//end of neuron group

};//end of mainmodule
